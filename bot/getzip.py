import os
import requests
import zipfile
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from io import BytesIO

def register_getzip(bot):
    @bot.message_handler(commands=['getzip'])
    def handle_getzip(message):
        args = message.text.split(maxsplit=1)
        if len(args) != 2 or not args[1].startswith("http"):
            bot.reply_to(message, "â— Báº¡n cáº§n nháº­p Ä‘Ãºng Ä‘á»‹nh dáº¡ng: `/getzip <url>`", parse_mode="Markdown")
            return

        chap_url = args[1].strip()
        sent_msg = bot.reply_to(message, "ğŸ” Äang xá»­ lÃ½, vui lÃ²ng chá»...")

        try:
            zip_data, total = get_zip_from_chapter(chap_url)

            if total == 0:
                bot.edit_message_text(chat_id=sent_msg.chat.id, message_id=sent_msg.message_id, text="âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh nÃ o trong trang.")
                return

            zip_data.seek(0)
            file_name = get_story_name_from_url(chap_url) + ".zip"

            # XÃ³a tin nháº¯n "Ä‘ang xá»­ lÃ½"
            bot.delete_message(chat_id=sent_msg.chat.id, message_id=sent_msg.message_id)

            # Gá»­i file zip
            bot.send_document(
                chat_id=message.chat.id,
                document=zip_data,
                visible_file_name=file_name,
                caption=f"âœ… ÄÃ£ táº£i xong {total} áº£nh tá»« chÆ°Æ¡ng truyá»‡n!"
            )

        except Exception as e:
            bot.edit_message_text(chat_id=sent_msg.chat.id, message_id=sent_msg.message_id, text=f"âŒ ÄÃ£ xáº£y ra lá»—i:\n`{str(e)}`", parse_mode="Markdown")

    def get_zip_from_chapter(chap_url):
        headers = {
            "Referer": chap_url,
            "User-Agent": "Mozilla/5.0",
        }

        response = requests.get(chap_url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        img_divs = soup.select("div.text-center div.lazy")
        img_urls = [div.get("data-src") for div in img_divs if div.get("data-src")]

        zip_buffer = BytesIO()

        story_name = get_story_name_from_url(chap_url)
        chapter_name = get_chapter_name_from_url(chap_url)

        with zipfile.ZipFile(zip_buffer, "w") as zipf:
            for idx, img_url in enumerate(img_urls):
                ext = img_url.split(".")[-1].split("?")[0]
                filename = f"{idx+1:03d}.{ext}"

                img_data = requests.get(img_url, headers=headers).content

                # Ghi file theo cáº¥u trÃºc thÆ° má»¥c trong zip
                zip_path = f"{story_name}/{chapter_name}/{filename}"
                zipf.writestr(zip_path, img_data)

        return zip_buffer, len(img_urls)

    def get_story_name_from_url(url):
        path_parts = urlparse(url).path.strip("/").split("/")
        # Giáº£ sá»­ URL kiá»ƒu /truyen/one-piece/chap-1084/
        if len(path_parts) >= 2 and path_parts[0].lower() == "truyen":
            # Thay dáº¥u "-" báº±ng dáº¥u cÃ¡ch
            return path_parts[1].replace("-", " ")
        else:
            # Fallback, thay "/" báº±ng "_"
            return urlparse(url).path.strip("/").replace("/", "_")

    def get_chapter_name_from_url(url):
        path_parts = urlparse(url).path.strip("/").split("/")
        for part in path_parts:
            if part.lower().startswith("chap"):
                return part.replace("-", " ")
        return "chapter"  # fallback